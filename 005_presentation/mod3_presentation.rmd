---
title: "Advances in the analysis of multivariate ecological data"
subtitle: "MOD3: Advanced data science"
author: "Jonathan Jupke"
institute: "University of Koblenz Landau"
date: "2021/01/07"
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: ["default", "libs/sydney.css", "libs/sydney-fonts.css"]
    nature:
      countIncrementalSlides: false
---
```{css, echo = FALSE}
.remark-code { font-family: 'Source Code Pro', 'Lucida Console', Monaco, monospace;
                                    font-size: 100%;
                                  }
}
```

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
```




<!--TODO abstand zwischen Bullets-->  
<!--# TODO serial slide-->   
<!--# TODO bullet color-->  

# Plan for today 

- What’s new in multivariate analysis?

- mvabund

- Vector GLM/GAM

- Latent Variable Models 

- Copulas 

- Hierarchical Modeling of Species Communities

- Neural Hierarchical Models 


---
class: inverse, center, middle 

# What’s new in multivariate analysis?

---

# ... or what's old

--

brainstrom : What Methods do you know? 

--

- PCA
- RDA
- PERMANOVA
- CA/ CCA
- Random Forests 
- Clustering Methods 

---
# Bi/Triplot

```{r load vegan, results='hide', echo = T, message = F}
library(vegan)
data(dune)
data(dune.env)
rda_object <- rda(dune ~ ., dune.env)
```

---
# Bi/Triplot
```{r, fig.width = 6, fig.height = 6, fig.align="center"}
plot(rda_object)
```

---
# What do most ordinations have in common? 

--

They are based on some notion of a distance metric

##fixed 
- PCA and RDA: Euclidean 
- CA and CCA: $\chi^2$-distance

--

##flexible 
- NMDS 
- PCoA
- dbRDA

---
# How does that differ from the univerate and why? 

--

In univariate analyses we mostly use models:
- linear model 
- linear mixed model 
- generalized linear model 
- generalized additive models 

--

$\rightarrow$ why not in multivariate analyses? 

---
class: middle, center

```{r, fig.align="center", echo = F}
knitr::include_graphics("old_pc.gif")
```

---
# The idea is old 

The Gaussian response model: 
$$Y_i = ce^{- \frac{(X_i - u)^2}{2t^2}} $$
--
Can be rewritten as a GLM:
$$Y_i = exp(ln(c) - \frac{u^2}{2t^2} + \frac{u}{t^2}x_i - \frac{1}{2t^2}x^2_i) = exp(b_1 + b_2 x_i + b_3 x_i^2)$$
--
with 
$$ t = \frac{1}{\sqrt{-2b_3}}; u = \frac{-b_2}{2b_3}; c =     exp(b_1 - \frac{b_2^2}{4b_3})$$ 
--
For M species and Q environmental variables we would need: $(1+2Q)M$ parameters. For 10 species and 5 variables 110 parameters.  

---
# Restricted Gaussian Regression 

gradients as linear combinations of measured variables: 

$$z_i = \Sigma_{p =  1}^Q \alpha_p x_{ip}$$
--
Plug gradients back into Gaussian regression
$$Y_i = ce ^{\frac{(z_i - u)^2}{2t^2}}$$ 

Depending on the number of gradients this reduces the number of parameters. 

---
# What is the model-based approach? 

Model-based approaches assume a parametric generative model

Terms are not consistent:  
Roberts (2019) vs. Warton *el al.* (2012) dissagree about wether CA is distance-based

Alternative: algorithm-based (Warton *et al.* 2015) 
Alternative 2: transformation-based  

"*Our constrained ordination model [...]* " Brittain *et al.* (2020)  
"*Many biologist fit CCA models [...]* " Yee (2004) 

---
background-image: url("figures/glm_error.png")
background-size: 500px
background-position: 50% 50%
<!-- Are models better  1-->
# Are models better? 

---
background-image: url("figures/WWW12_1.png")
background-size: 800px
background-position: 50% 50%
<!-- Are models better  2-->
# Are models better? 

Every distance metric assumes a mean variance relationship  

.footnote[Warton *et al.* (2012)]
---
background-image: url("figures/WWW12_2.png")
background-size: 400px
background-position: 50% 75%

# Are models better? 

Every distance metric assumes a mean variance relationship  



.footnote[Warton *et al.* (2012)]
---
background-image: url("figures/WWW12_3.png")
background-size: 400px
background-position: 50% 75%

# Are models better? 

Every distance metric assumes a mean variance relationship  



.footnote[Warton *et al.* (2012)]
---
background-image: url("figures/szöcs15_1.png")
background-size: 400px
background-position: 50% 75%

# Are models better? 



.footnote[Szöcs *et al.* (2015)]
---
background-image: url("figures/jupke20_1.png")
background-size: 800px
background-position: 50% 50%

# Are models better? 

.footnote[Jupke *et al.* (2020)]
---
class: inverse, center, middle 

# mvabund

---
# mvabund 

R package published in 2012  (Wang et al. 2012)

**M**ulti**v**ariate **Abund**ance data  

Multivariate
- many, possibly correlated responses 

Abundance
- strong mean-variance relationship 
---
# Multivariate GLMM

We could use mixed models and model the taxon as a random effect.
$$Abundace \sim species\ + variable1\ + variable2\ + (0 + species|sample)$$
1. $y_{ij}$ are independand, conditional on mean  $\mu_{ij}$
2. Conditional on $\mu_{ij}$, data come from a .blue[known distribution]  
3. straight line relationship between some function $\mu_{ij}$ and x, with error $\epsilon_{ij}$
$$g(\mu_{ij}) = \beta_0j + x^T_j \beta_j + \epsilon_{ij}$$
4. $\epsilon$ are normally distributed. They introduce correlation between response within observatios. 
$$\epsilon_{ij} \sim MVN(0, \Sigma)$$
---
# Implementations in R

- lme4 
- MCMCglmm 
- Purpose written code (e.g. Pollock et al 2014)

---
# Whats the problem with this approach? 

|  # responses | # parameters in $\Sigma$ |
| :---- |:--- |
| 5     | 15 |
| 10    | 55 |
| 20    | 210 |
| 40    |  820 |

- No convergence in ML GLMM  
- long run time, not all parameters converge, and big influence of prior as $\frac{\# data}{\#parameters}$ is small. 
  
---
# Simplify
mvabund uses design-based inference and assumes simple correlation structures.  
This is fine if we are primarily interested in species environment relationships  

--
Multivariate: row resampling for inference, preserves species correlations  
Abundance: separate GLM for each species
---
# Test statistics  

default: $\Sigma\ Likelihood\ Ratios$
\begin{align}
L & = 2 \times (l_M - l_m)  \\
L &\sim \chi^2_{p_M - p_m} \\  
\end{align}

This does not account for correlations in the statistic but in the pseudo-*p*-value.  
--
  
  
Alternatives:      
  
Wald statistic   
\begin{align}
W &= \frac{(\beta_m - \beta_0)^2}{var(\beta_m)} \\
z &= \sqrt(W)
\end{align}

Score statistic  
see e.g. Dunn \& Smyth (2018)

---
# Correlation options
  
.blue["I"]: No correlation, default setting   
.blue["R"]: Assumes correlation, cf. mixed model  
.blue["shrink"]: middle option, shrinks correlation matrix to $I$ with ridge regularization (Warton (2008))  
  
For R and shrink LR is not available. They are estimated with generalized estimation equations (Warton 2011) which do not produce likelihoods. 

---

```{r}
library(mvabund)
data("Tasmania")
attach(Tasmania)
head(copepods[,1:3])
```
```{r}
tasmvabund <- mvabund(copepods)
class(tasmvabund)
```
---
```{r, message = FALSE, fig.align="center", warning=FALSE, fig.height=6}
plot(tasmvabund~treatment, col = as.numeric(block))
```
---
```{r, message = FALSE, warning=FALSE, fig.align="center",  fig.height=7}
meanvar.plot(copepods~tr.block, col = as.numeric (treatment))
```
---
# Fitting a model 
```{r}
tas.nb <- manyglm(copepods ~ block*treatment, 
                  family = "negative.binomial")
```


$$Y_{ij} \sim NB(\mu_{jkl}, \phi_j)$$
$$log(\mu_{jkl}) = intercept_j + block_{jkl} + treatment_{jl} + block \times treatment_{jkl}$$
---
# Checking model assumptions 
```{r mvabund Checking model assumptions 1, fig.align="center", fig.height=6, fig.width=6}
plot.manyglm(tas.nb, which = 1)
```
.footnote[Dunn & Smyth (1996)]
---
# Checking model assumptions
```{r mvabund Checking model assumptions 2, fig.align="center", fig.height=6, fig.width=6}
plot.manyglm(tas.nb, which = 2)
```
.footnote[Dunn & Smyth (1996)]
---
# Checking model assumptions
```{r mvabund Checking model assumptions 3, fig.align="center", fig.height=6, fig.width=6}
plot.manyglm(tas.nb, which = 3)
```
.footnote[Dunn & Smyth (1996)]
---
# Testing Hypotheses

```{r mvabund Testing Hypotheses, comment=""}
# anova_out <- anova(tas.nb, p.uni = "adjusted")
```
.scroll-box-16[
```{r}
# anova_out
```
]
---
```{r}
library(lattice)
a <- max(abs(coef(tas.nb)))
colort <- colorRampPalette(c("blue", "white", "red"))
plot.tas <- levelplot(t(as.matrix(coef(tas.nb))), ylab = "", xlab  = "", col.regions = colort(100), at=seq(-a,a,length = 100), scales = list( x= list(rot = 45)))
print(plot.tas)
```
---
```{r}
tas_pred = predict(tas.nb, type = "response")
matplot(t(tas_pred[c(1,3),]), type = "l", xaxt = "n", log = "y", ylab = "Mean abundance [log]")
axis(1, at =1:12, labels = colnames(copepods), las = 3)
legend("topright", legend = levels(treatment), col = 1:2, lty = 1:2)
```


---
# Traits 
Not discussed in lecture. See here for introduction:  
https://rpubs.com/dwarton/68823

---
class: inverse, center, middle 

# Vector Genralized Models 

---
```{r load VGAM, message=FALSE}
library(VGAM)
```

```{r}
data(spider)
knitr::kable(head(spider$abund[,1:5]), format = "html")
```
---
.scroll-output[
```{r run cqo, message=FALSE, warning=F}
set.seed(1234)
p1ut.hs <- cqo(
  cbind(
    Alopacce, Alopcune, Alopfabr, Arctlute, Arctperi,
    Auloalbi, Pardlugu, Pardmont, Pardnigr, Pardpull,
    Trocterr, Zoraspin) ~ WaterCon + BareSand + 
    FallTwig + CoveMoss + CoveHerb + ReflLux,
    family = poissonff, data = hspider, eq.toler = FALSE, trace = FALSE)
S <- ncol(depvar(p1ut.hs)) # Number of species
clr <- (1:(S+1))[-7] # Omits yellow
lvplot(p1ut.hs, y = TRUE, lcol = clr, pch = 1:S, pcol = clr)

```
]
---
```{r cqo persp plot}
persp(p1ut.hs, col = clr, label = TRUE) # Perspective plot
```

---
# Predictors 
```{r cqo 1d  variables}
round(concoef(p1ut.hs), digits = 2)
```
---

.small[
```{r cqo run 2d, echo=T, results='hide'}
p2et.hs <- cqo(cbind(Alopacce, Alopcune, Alopfabr, Arctlute, Arctperi,Auloalbi, Pardlugu, Pardmont, Pardnigr, Pardpull,Trocterr, Zoraspin)
               ~ WaterCon + BareSand + FallTwig + CoveMoss + CoveHerb + ReflLux,
               poissonff, data = hspider, Crow1positive = FALSE, Rank = 2,
               I.toler = TRUE, Bestof = 2)
```
]
---

```{r cqo 2d persp, echo=T, results='hide'}
persp(p2et.hs, xlim = c(-6, 5), ylim = c(-6, 3), theta = 120, phi = 20)
```

---
class: inverse, center, middle 

# Latent Variable Models 

---
class: inverse, center, middle 

# Copulas 

---
class: inverse, center, middle 

# Hierarchical modeling of species communities 

---
class: inverse, center, middle 

# Hierarchical Neural networks 

--- 



