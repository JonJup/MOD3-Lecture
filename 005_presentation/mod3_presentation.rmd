---
title: "Advances in the analysis of multivariate ecological data"
subtitle: "MOD3: Advanced data science"
author: "Jonathan Jupke"
institute: "University of Koblenz-Landau"
date: "2021/01/07"
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: ["default", "libs/sydney.css", "libs/sydney-fonts.css"]
    nature:
      countIncrementalSlides: false
      navigation:
        scroll: false # disable slide transitions by scrolling

---
```{css, echo = FALSE}
.remark-code { font-family: 'Source Code Pro', 'Lucida Console', Monaco, monospace;
                                    font-size: 100%;
                                  }
}
```

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
library(corrplot)
library(UncertainOrd)
```

<!--TODO Abstand zwischen Bullets-->  
<!--# TODO serial slide-->   
<!--# TODO bullet color-->  

# Plan for today 

- What’s new in multivariate analysis?

- mvabund

- Vector GLM/GAM

- Latent Variable Models 

- Copulas 

- Hierarchical Modeling of Species Communities

- Neural Hierarchical Models 


---
class: inverse, center, middle 

# What’s new in multivariate analysis?

---

# ... and what's old? 

--

brainstrom : What Methods do you know? 

--

- PCA
- RDA
- PERMANOVA
- CA/ CCA
- Random Forests 
- Clustering Methods 

---
# Bi/Triplot

```{r load vegan, results='hide', echo = T, message = F}
library(vegan)
data(dune)
data(dune.env)
rda_object <- rda(dune ~ ., dune.env)
```

---
# Bi/Triplot
```{r, fig.width = 6, fig.height = 6, fig.align="center"}
plot(rda_object)
```

---
# What do most ordinations have in common? 

--

They are based on some notion of a distance metric

##fixed 
- PCA and RDA: Euclidean 
- CA and CCA: $\chi^2$-distance

--

##flexible 
- NMDS 
- PCoA
- dbRDA

---
# How does that differ from the univerate and why? 

--

In univariate analyses we mostly use models:
- linear model 
- linear mixed model 
- generalized linear model 
- generalized additive models 

--

$\rightarrow$ why not in multivariate analyses? 

---
class: middle, center

```{r, fig.align="center", echo = F}
knitr::include_graphics("old_pc.gif")
```

---
# The idea is old 

The Gaussian response model: 
$$Y_i = ce^{- \frac{(X_i - u)^2}{2t^2}} $$
--
Can be rewritten as a GLM:
$$Y_i = exp(ln(c) - \frac{u^2}{2t^2} + \frac{u}{t^2}x_i - \frac{1}{2t^2}x^2_i) = exp(b_1 + b_2 x_i + b_3 x_i^2)$$
--
with 
$$ t = \frac{1}{\sqrt{-2b_3}}; u = \frac{-b_2}{2b_3}; c =     exp(b_1 - \frac{b_2^2}{4b_3})$$ 
--
For M species and Q environmental variables we would need: $(1+2Q)M$ parameters. For 10 species and 5 variables 110 parameters.  

---
# Restricted Gaussian Regression 

gradients as linear combinations of measured variables: 

$$z_i = \Sigma_{p =  1}^Q \alpha_p x_{ip}$$
--
Plug gradients back into Gaussian regression
$$Y_i = ce ^{\frac{(z_i - u)^2}{2t^2}}$$ 

Depending on the number of gradients this reduces the number of parameters. 

---
# What is the model-based approach? 

Model-based approaches assume a parametric generative model

Terms are not consistent:  
Roberts (2019) vs. Warton *el al.* (2012) dissagree about wether CA is distance-based

Alternative: algorithm-based (Warton *et al.* 2015) 
Alternative 2: transformation-based  

"*Our constrained ordination model [...]* " Brittain *et al.* (2020)  
"*Many biologist fit CCA models [...]* " Yee (2004) 

---
background-image: url("figures/glm_error.png")
background-size: 500px
background-position: 50% 50%
<!-- Are models better  1-->
# Are models better? 

---
background-image: url("figures/WWW12_1.png")
background-size: 800px
background-position: 50% 50%
<!-- Are models better  2-->
# Are models better? 

Every distance metric assumes a mean variance relationship  

.footnote[Warton *et al.* (2012)]
---
background-image: url("figures/WWW12_2.png")
background-size: 400px
background-position: 50% 75%

# Are models better? 

Every distance metric assumes a mean variance relationship  

.footnote[Warton *et al.* (2012)]
---
background-image: url("figures/WWW12_3.png")
background-size: 400px
background-position: 50% 75%

# Are models better? 

Every distance metric assumes a mean variance relationship  



.footnote[Warton *et al.* (2012)]
---
background-image: url("figures/szöcs15_1.png")
background-size: 400px
background-position: 50% 75%

# Are models better? 



.footnote[Szöcs *et al.* (2015)]
---
background-image: url("figures/jupke20_1.png")
background-size: 800px
background-position: 50% 50%

# Are models better? 

.footnote[Jupke *et al.* (2020)]
---
class: inverse, center, middle 

# mvabund

---
# mvabund 

R package published in 2012  (Wang et al. 2012)

**M**ulti**v**ariate **Abund**ance data  

Multivariate
- many, possibly correlated responses 

Abundance
- strong mean-variance relationship 
---
# Multivariate GLMM

We could use mixed models and model the taxon as a random effect.
$$Abundace \sim species\ + variable1\ + variable2\ + (0 + species|sample)$$
1. $y_{ij}$ are independand, conditional on mean  $\mu_{ij}$
2. Conditional on $\mu_{ij}$, data come from a .blue[known distribution]  
3. straight line relationship between some function $\mu_{ij}$ and x, with error $\epsilon_{ij}$
$$g(\mu_{ij}) = \beta_0j + x^T_j \beta_j + \epsilon_{ij}$$
4. $\epsilon$ are normally distributed. They introduce correlation between response within observatios. 
$$\epsilon_{ij} \sim MVN(0, \Sigma)$$
---
# Implementations in R

- lme4 
- MCMCglmm 
- Purpose written code (e.g. Pollock et al 2014)

---
# Whats the problem with this approach? 

|  # responses | # parameters in $\Sigma$ |
| :---- |:--- |
| 5     | 15 |
| 10    | 55 |
| 20    | 210 |
| 40    |  820 |

- No convergence in ML GLMM  
- long run time, not all parameters converge, and big influence of prior as $\frac{\# data}{\#parameters}$ is small. 
  
---
# Simplify
mvabund uses design-based inference and assumes simple correlation structures.  
This is fine if we are primarily interested in species environment relationships  

--
Multivariate: row resampling for inference, preserves species correlations  
Abundance: separate GLM for each species
---
# Test statistics  

default: $\Sigma\ Likelihood\ Ratios$
\begin{align}
L & = 2 \times (l_M - l_m)  \\
L &\sim \chi^2_{p_M - p_m} \\  
\end{align}

This does not account for correlations in the statistic but in the pseudo-*p*-value.  
--
  
  
Alternatives:      
  
Wald statistic   
\begin{align}
W &= \frac{(\beta_m - \beta_0)^2}{var(\beta_m)} \\
z &= \sqrt(W)
\end{align}

Score statistic  
see e.g. Dunn \& Smyth (2018)

---
# Correlation options
  
.blue["I"]: No correlation, default setting   
.blue["R"]: Assumes correlation, cf. mixed model  
.blue["shrink"]: middle option, shrinks correlation matrix to $I$ with ridge regularization (Warton (2008))  
  
For R and shrink LR is not available. They are estimated with generalized estimation equations (Warton 2011) which do not produce likelihoods. 

---

```{r}
library(mvabund)
data("Tasmania")
attach(Tasmania)
head(copepods[,1:3])
```
```{r}
tasmvabund <- mvabund(copepods)
class(tasmvabund)
```
---
```{r, message = FALSE, fig.align="center", warning=FALSE, fig.height=6}
plot(tasmvabund~treatment, col = as.numeric(block))
```
---
```{r, message = FALSE, warning=FALSE, fig.align="center",  fig.height=7}
meanvar.plot(copepods~tr.block, col = as.numeric (treatment))
```
---
# Fitting a model 
```{r}
tas.nb <- manyglm(copepods ~ block*treatment, 
                  family = "negative.binomial")
```


$$Y_{ij} \sim NB(\mu_{jkl}, \phi_j)$$
$$log(\mu_{jkl}) = intercept_j + block_{jkl} + treatment_{jl} + block \times treatment_{jkl}$$
---
# Checking model assumptions 
```{r mvabund Checking model assumptions 1, fig.align="center", fig.height=6, fig.width=6}
plot.manyglm(tas.nb, which = 1)
```
.footnote[Dunn & Smyth (1996)]
---
# Checking model assumptions
```{r mvabund Checking model assumptions 2, fig.align="center", fig.height=6, fig.width=6}
plot.manyglm(tas.nb, which = 2)
```
.footnote[Dunn & Smyth (1996)]
---
# Checking model assumptions
```{r mvabund Checking model assumptions 3, fig.align="center", fig.height=6, fig.width=6}
plot.manyglm(tas.nb, which = 3)
```
.footnote[Dunn & Smyth (1996)]
---
# Testing Hypotheses

```{r mvabund Testing Hypotheses, comment=""}
# anova_out <- anova(tas.nb, p.uni = "adjusted")
```
.scroll-box-16[
```{r}
# anova_out
```
]
---
```{r}
library(lattice)
a <- max(abs(coef(tas.nb)))
colort <- colorRampPalette(c("blue", "white", "red"))
plot.tas <- levelplot(t(as.matrix(coef(tas.nb))), ylab = "", xlab  = "", col.regions = colort(100), at=seq(-a,a,length = 100), scales = list( x= list(rot = 45)))
print(plot.tas)
```
---
```{r}
tas_pred = predict(tas.nb, type = "response")
matplot(t(tas_pred[c(1,3),]), type = "l", xaxt = "n", log = "y", ylab = "Mean abundance [log]")
axis(1, at =1:12, labels = colnames(copepods), las = 3)
legend("topright", legend = levels(treatment), col = 1:2, lty = 1:2)
```


---
# Traits 
Not discussed in lecture. See here for introduction:  
https://rpubs.com/dwarton/68823

---
class: inverse, center, middle 

# Vector Genralized Models 
---
# VGLMs
.footnote[see Dobson & Barnett (2018) for more on the exponential family]

... are an extension of GLMs   
GLMs are restricted to distributions from the .blue[exponential family].   
VGLMS are not.  
VGLMs can have multiple linear predictors, for different parameters.  
Explanatroy variables can differ between predictors.
---
# The exponential family

$$f(x, \theta) = s(x)\ t(\theta)\ exp (a(y)\ b(\theta))$$
--
$$f(x, \theta) = exp(a(y)\ b(\theta) + c(\theta) + d(y)) $$
with $c(\theta) = exp(t(\theta))$ and $d(y) = exp(s(y))$

--

.blue[Poisson]
\begin{align}
f(x,\lambda) &= \frac{\lambda^y e^{-\lambda}}{y!}\\
\theta &= \lambda\\
f(x, \theta) &= exp(log(\theta)\ y - \theta - log(y!))
\end{align}


---
# Reduced Rank VGLM  

Reduce the dimensions, i.e. number of predictors $P$ by reduced rank regression   

--

Create latent variables $\nu$ from subset of environmental variables $X$

--

$x = (x_1, x_2)$ and $B = c(B_1,B_2)$  

--
$$B_2 = A C^T$$ 
$$\nu = C^T x_2\ \ \ \ \ \ (site\ scores)$$
$$\eta = B_1^T x_1 + A C^Tx_2 = B_1^T x_1 + A \nu$$
--
$\rightarrow$ Reduced Rank Regression is the same as RDA! 


---

# Quadratic RR-VGLM

In ecology, unimodal responses are the norm (Oksanen & Minchin, 2002)  

--

quadratic linear predictor  

--

$$\eta = B_1^T x_1 + A C^Tx_2 = B_1^T x_1 + A \nu\ \ \ \ \ \ \ ordinary\ RR-VGLM$$
$$\eta_s = \beta_{1(s)}^T  + \beta_{2(s)}\ \nu + \beta_{3(s)}\ \nu^2\ \ \ \ \ \ \ quadratic\ RR-VGLM$$
$$ log\ \mu_s(\nu) = \eta_s = \alpha_s - \frac{1}{2} \bigg( \frac{\nu - u_s}{t_s} \bigg)^2 $$


---
# Hunting Spider Data

from ter Braak (1986)  

```{r load VGAM, message=FALSE, echo = F}
library(VGAM);library("DT"); library("dplyr");library(kableExtra)
data(hspider)
```

```{r, echo = F}

hspider %>% 
  kbl(format = "html") %>% 
  scroll_box(height = "400px", width = "700px")

```
---
# Rank-1 Poisson CQO
.scroll-output[
```{r run cqo, message=FALSE, warning=F}
set.seed(1234)
hspider[, 1:6] <- scale(hspider[, 1:6]) # Standardized environmental variables
p1ut.hs <- cqo(cbind(Alopacce, Alopcune, Alopfabr, 
                     Arctlute, Arctperi, Auloalbi, 
                     Pardlugu, Pardmont, Pardnigr, 
                     Pardpull, Trocterr, Zoraspin) ~ 
                 WaterCon + BareSand + FallTwig + CoveMoss + 
                 CoveHerb + ReflLux,
               family = poissonff, 
               data = hspider, 
               eq.toler = FALSE, 
               trace = FALSE)
```
]

```{r options cqo plot1, echo =F}
S <- ncol(depvar(p1ut.hs)) # Number of species
clr <- (1:(S+1))[-7] # Omits yellow
```
---
# Latent Variable Plot 
```{r cqo lvplot 1, message=FALSE, warning=F, fig.align="center"}
lvplot(p1ut.hs, y = TRUE, lcol = clr, pch = 1:S, pcol = clr)
```

---
# 2d Perspective Plot 
```{r CQO persp plot, fig.align="center"}
persp(p1ut.hs, col = clr, label = TRUE) # Perspective plot
```

---
# Constrained Coefficients
```{r 1d CQO variables}
concoef(p1ut.hs) %>%  as.vector() %>% round(2) -> p1ut_coef
names(p1ut_coef) <- row.names(concoef(p1ut.hs))
print(p1ut_coef)
```

--
.scroll-box-8[
```{r 1d CQO Tolerances}
Tol(p1ut.hs)[1, 1, ]
```
]
---
# Let's add a second gradient
.small[
```{r run 2d CQO, echo=T, results='hide'}
p2et.hs <- cqo(cbind(Alopacce, Alopcune, Alopfabr, Arctlute, Arctperi,Auloalbi, Pardlugu, Pardmont, Pardnigr, ... = Pardpull,Trocterr, Zoraspin)
               ~ WaterCon + BareSand + FallTwig + CoveMoss + CoveHerb + ReflLux,
               poissonff, data = hspider, Crow1positive = FALSE, Rank = 2,
               I.toler = TRUE, Bestof = 2)
```
]
---
# 2 Graident Latent Variable Plot 

```{r, 2d latent variable plot, fig.align="center" , echo = F}
lvplot(p2et.hs, ellipse = FALSE, label = TRUE, xlim = c(-3, 5.7),
C = TRUE, Ccol = "brown", sites = TRUE, scol = "gray50",
pcol = "blue", pch = "+", chull = TRUE, ccol = "gray50")
```

---
# 3d Perspective plot
```{r CQO 2d persp plot, echo=T, results='hide', fig.align="center"}
persp(p2et.hs, xlim = c(-6, 5), ylim = c(-6, 3), 
      theta = 120, phi = 20)
```
---
# Extended ouput 

.scroll-output[
```{r CQO coefficients}
coef(p2et.hs)
```

]
---
# Constained Additive Ordination 
Besides VGLMs, additive models VGAMs can be fitted.  
- Syntax similar to CQO 
- new argument: *df1.nl*: effective non-linear degrees of freedom  
- controls how smooth the output is (0 = linear)
.scroll-output[
```{r fit CAO}
set.seed(1)
# p1cao.hs <- cao(cbind(Alopacce, Alopcune, Alopfabr, Arctlute, Arctperi, Auloalbi,
#                       Pardlugu, Pardmont, Pardnigr, Pardpull, Trocterr, Zoraspin) ~
#                 WaterCon + BareSand + FallTwig + CoveMoss + CoveHerb + ReflLux,
#                 poissonff, data = hspider, Rank = 1, df1.nl = 2, Bestof = 10, 
#                 Crow1positive = FALSE)
```

]
---
# CAO single species plots

```{r, cao plot, fig.align="center", echo = F}
# par(mfrow = c(3,3))
# plot(p1cao.hs, lcol = "blue", lwd = 2, ylim = c(-5, 5), xlab = "", ylab = "")
```
---
```{r, cao persp, fig.align="center", echo = F}
# par(mfrow = c(1,1))
# persp(p1cao.hs,col = clr, label = TRUE)
```
---
# In practice 

- They are not commonly used 
- individual GLMs outperformed CQO in predicting species ranges (Baselga & Araújo, 2009)
- CQO better for rare species but GLM predicts better (Bonthoux *et al.* 2013) 
- mvabund glms differentiated between noise and causal variables better than CQO (Jupke & Schäfer, 2020)
- CQO and CAO predict better (but still bad) than GLM and GAM to dissimilar conditions (Maguire *et. al.*, 2016) 
- Applied studies mostly with fish (e.g. Vilizzi et al. (2012), Top *et al.* (2016))
- "limitations on the number of species, steepness of the learning curve and low numerical stability of the algorithm" (ter Braak & Šmilauer 2015)
---
class: inverse, center, middle
# Latent Variable Models 
---
# Random-effects ordination 

.footnote[Walker & Jackson (2011)]

- unconstrained ordination through random effect model  

--

- $\hat{y_i} = a + \mathbf{B}\mathbf{x}_i$

--

- $a = [a_i]$ is a column vector of intercepts with one for each variable

--

- $B=[b_{jk}]$ matrix of coefficients relating observed variables to axes (latent variables)

--

- assume standard normal distribution of axis scores

--

- fit $\mathbf{B}$ and $x_i$ iteratively with ML 

--

- only presence-absence or normal distribution

--

- implemented in reo R package



---

# BORAL

- Hui *et al* (2015) extend the basic idea of Walker & Jackson (2011) to GLMs 

--

- Hui (2016): Bayesian Ordination and Regression Analysis

--

- (un)constrained Ordination with MCMC estimation 

--

- latent variables are biotic associations or missing covariates.

--

- $log(\mu_{ij}) = \alpha_i + \theta_{0j} + z_{i1} \theta_{1j} + z_{i2}\theta_{2j}=\alpha_i + \theta_{0j} +\mathbf{z_i^T}\mathbf{\theta_j}$

--

- Priors:
- $\theta_{0j} \sim N(0,100)$
- $\theta_{\lambda} \sim U(0,50)\ \forall\ \theta_{\lambda}:0\notin \theta_{\lambda}$ 
- $\theta_j; \alpha_i \sim N(0,20)$
---

# Co-occurence is not Interaction 

.footnote[Blanchet *et al.* 2020]

- Species occurrences depend on the environment  

--

- Indirect species associations   

--

- Sampling scale influences measures of co-occurrence  

--

- Appropriate statistical inference requires a very large sample size  

--

- Interactions are often asymmetric   
---
# BORAL in Action
.scroll-output[
```{r echo=FALSE}
fit_unconstrained_po <-readRDS("../003_processed_data/boral_unconstrained_poisson.RDS")
```

```{r}
pacman::p_load(boral, rjags, mvabund, UncertainOrd)
data(spider)
Y <- spider$abund
#fit_unconstrained_po <- boral(y = Y, family = "poisson", lv.control = list(num.lv = 2),row.eff = "fixed",save.model=TRUE)
summary(fit_unconstrained_po)
```
]
---
# Check model assumptions

```{r check boral 1, fig.align="center", fig.height=7, fig.width=7, echo=FALSE}
par(mfrow=c(2,2))
plot(fit_unconstrained_po)
```
---
# Check model assumptions - NB
```{r check boral 2, fig.align="center", fig.height=7, fig.width=7, echo=FALSE}
fit_unconstrained_nb <-readRDS("../003_processed_data/boral_unconstrained_negbinom.RDS")
par(mfrow=c(2,2))
plot(fit_unconstrained_nb)
```
---
# Ordination Diagram
```{r ordiplot boral 1, fig.align="center", fig.height=7, fig.width=7, echo=FALSE}
suppressMessages(lvsplot(fit_unconstrained_nb))
```
---
```{r boral load contrained, echo=FALSE}
fit_constrained_nb <- readRDS("../003_processed_data/boral_constrained_negbinom.RDS")
```

# Constrained Ordination 
.scroll-output[
```{r boral fit constrained}
X <- scale(spider$x)
#fit_constrained_nb <- boral(y = Y, X = X, family = "negative.binomial", lv.control = list(num.lv = 2), save.model = TRUE)
summary(fit_constrained_nb)
```
]
---
# Correlation plots 
```{r boral correlation plots, echo=FALSE, fig.align="center", fig.width=8, fig.height=8}
envcors <- get.enviro.cor(fit_constrained_nb)
rescors <- get.residual.cor(fit_constrained_nb) 
par(mfrow=c(1,1))
corrplot(
        envcors$sig.cor,
        type = "lower",
        diag = FALSE,
        title =  "Correlations due to covariates", 
        mar = c(3,0.5,2,1), tl.srt = 45) 
```
---
# Correlation plots 
```{r boral correlation plots, echo=FALSE, fig.align="center", fig.width=8, fig.height=8}
envcors <- get.enviro.cor(fit_constrained_nb)
rescors <- get.residual.cor(fit_constrained_nb) 
par(mfrow=c(1,1))
corrplot(
        rescors$sig.cor,
        type = "lower",
        diag = FALSE,
        title =  "Residual correlations",
        mar = c(3, 0.5, 2, 1),
        tl.srt = 45
)
```
---
# Uncertainty in latent variable models
- R package UncertainOrd (Hoegh & Roberts, 2020)
- based on 95% credible intervals

```{r load uncertainord file, echo=FALSE}
uncertain_plot <- readRDS("../003_processed_data/boral_uncertainplot.RDS")
par(mfrow=c(1,1))
```
.scroll-output[
```{r, echo=FALSE}
print(uncertain_plot)
```
]
---
# Can we include traits in this? 

- as parameters for the priors  

$$\theta_{ij} \sim N(t_j^T \kappa_0, \mathbf{\sigma}^2_0)$$
$$\beta_{jk} \sim N(\mathbf{t_j^T \kappa_K, \sigma^2_k})$$

---
# GLLVM package 

- see Nikku *et al.* (2019b)

- Uses recenet advances in ML estimation (Hui *et al.* 2017a; Niku *et al.*, 2017), computation (Kristensen et al., 2016), and parametrization (Niku et al., 2019a) to speed up computations. 

---
```{r}
# library(gllvm);library(corrplot);library(gclus)
# data("antTraits")
# y <- as.matrix(antTraits$abund)
# X <- scale(as.matrix(antTraits$env))
# TR <- antTraits$traits
```
---
# Unconstrained ordination with gllvm
.scroll-output[
```{r}
# fit_uo_po <- gllvm(y, family = poisson())
# fit_uo_nb <- gllvm(y, family = "negative.binomial")
# fit_uo_po
# fit_uo_nb
# par(mfrow = c(1,2))
# plot(fit_uo_nb, which = 1)
# plot(fit_uo_po, which = 1)
# plot(fit_uo_nb, which = 2)
# plot(fit_uo_po, which = 2)
# plot(fit_uo_nb, which = 3)
# plot(fit_uo_po, which = 3)
```
]
---
# Biplot with gllvm 

```{r gllvm unconstrained biplot, fig.align = "center", fig.height=7, echo = F}
# ordiplot(fit_uo_nb, biplot = TRUE, ind.spp = 15, xlim = c(-3,3) , ylim = c(-2, 1.6))
```
---
# Constrained Ordination with gllvm 
```{r}
# fit_co_nb2 <- gllvm(y, X, num.lv = 2, 
#                     formula = ~ Bare.ground + Shrub.cover + Volume.lying.CWD, 
#                     family = "negative.binomial")
# fit_co_nb3 <- gllvm(y, X, num.lv = 3, 
#                     formula = ~ Bare.ground + Shrub.cover + Volume.lying.CWD, 
#                     family = "negative.binomial")
```
---
# Biplot of constrained ordination 
```{r gllvm constrained biplot, echo = F, fig.align ="center"}
# ordiplot(fit_co_nb3, biplot = T)
```
---
# Coefficient plot 
```{r gllvm constrained coefficient plot, echo = F, fig.align = "center", fig.width = 10}
# coefplot(fit_co_nb3, cex.ylab = 0.7, mar = c(4,9,2,1), 
#          xlim.list = list(NULL, NULL, c(-4,4)))

```
---
# Residual Correlation plot 
```{r gllvm Residual Correlation plot, echo = F, fig.align="center"}
# cr <- getResidualCor(fit_co_nb3)
# par(mfrow = c(1,1))
# corrplot(cr[order.single(cr), order.single(cr)], diag = FALSE, type = "lower", method = "square", tl.cex = 0.8, tl.srt = 45, tl.col = "red")
```
---
# Fitting a Fourth Corner Model
```{r fitting 4th corner gllvm}
# fit_4th <- gllvm(y, X, TR, 
#                  family = "negative.binomial", 
#                  num.lv = 2, 
#                  formula = y ~ 
#                    (Bare.ground + Shrub.cover + Volume.lying.CWD) +
#                    (Bare.ground + Shrub.cover + Volume.lying.CWD) :  
#                    (Pilosity + Polymorphism + Webers.length))

```
---
# Fourth Corner Interaction Plot
```{r, echo = F, fig.align = "center"}
# fourth <- fit_4th$fourth.corner
# colort <- colorRampPalette(c("blue", "white", "red"))
# a <- max( abs(fourth) )
# plot.4th <- lattice::levelplot((as.matrix(fourth)), xlab = "Environmental Variables", 
#                       ylab = "Species traits", col.regions = colort(100), cex.lab =1.3,
#                       at = seq(-a, a, length = 100), scales = list(x = list(rot = 45)))
# plot.4th
```
---
# Do Traits matter here? 
```{r}
# fit_4th2 <- gllvm(y, X, TR, family = "negative.binomial", num.lv = 2, 
#                   formula = y ~ (Bare.ground + Shrub.cover + Volume.lying.CWD))
# anova(fit_4th, fit_4th2)
```

---
class: inverse, center, middle 

# Hierarchical modeling of species communities 
---
class: inverse, center, middle 
# Copulas 
---
# What are Copulas? 
- a Copula is a function $C()$ that .blue[couples] marginal distributions

--

- they combine marginal distributions $f_1, ..., f_d$ to a d-dimensional multivariate distribution $h()$

--

- Formally expressed in Sklar's Theorem (Sklar, 1959): 
$$ h(x) = C(f_1(x), ..., f_d(x))$$
--

- the marginals $f_1,...,f_d$ must be standard uniform $U(0,1)$ 

--

- all marginals can be mapped to $U(0,1)$ with probability integral transform (PIT)

---
background-image: url("figures/Anderson2019_1.png")
background-size: 700px
background-position: 50% 80%
# PIT continuous to discrete 
.footnote[Anderson *et al.* (2019)]
---
background-image: url("figures/Anderson2019_2.png")
background-size: 700px
background-position: 50% 80%
# Pit discrete to continuous
.footnote[Anderson *et al.* (2019)]

---

# Examples of Copulas
.content-box-blue[Independence Copula]
 
$$\Pi(\mathbf{u}) = \prod_{j=1}^du_j\ , \ \ u\ \epsilon\ [0,1]^d$$
.content-box-blue[bivariate Frank Copula]  
$$C_\theta^F (\mathbf{u}) = - \frac{1}{\theta}\ \log \bigg(1 + \frac{(exp(-\theta u_1)-1)(exp(-\theta u_2)-1)}{exp(-\theta)-1} \bigg)$$ 
.content-box-blue[Calyton Copula]  
$$C_\theta^C (\mathbf{u}) = max(u_1^{-\theta} + u_2^{-\theta} -1,0 )^{-1/\theta} $$
---
background-image: url("figures/Anderson2019_4.png")
background-size: 500px
background-position: 50% 90%
# What's it good for? 
- disentangle dependence and marginals 
- correlation coefficients are dependent of marginals as dependence structures



.footnote[Anderson *et al.* (2019)]
---
# How can we use it? 
- Roadmap provided by Anderson *et al.* (2019)  

i) identify marginals  

--

ii) Identify significant associations among species to model

--

iii) Fit Copula model 

--

iv) draw random samples from copulas 

---


---
background-image: url("figures/Anderson2019_3.png")
background-size: 700px
background-position: 50% 80%
# Simulate from copulas
.footnote[Anderson *et al.* (2019)]
---
background-image: url("figures/gosh2020b_1.png")
background-size: 700px
background-position: 50% 80%

# Tails associations 

.footnote[Gosh *et al.* (2020b)]
---
background-image: url("figures/gosh2020b_2.png")
background-size: 700px
background-position: 50% 80%

# Tails associations 

.footnote[Gosh *et al.* (2020b)]

---
background-image: url("figures/popovic2019_1.png")
background-size: 500px
background-position: 60% 80%
# Disentangaling species associations

- Popovic *et al.* 2019 and ecoCopula package

- Three reasons for two species to co-occur: 
  + environment
  + mediator species
  + direct association 

.footnote[Popovic *et al.* (2019)]
---
# Gaussian copula graphical models

- graphical models estimate the precision matrix $\Omega$ 

--

- $\Omega = \Sigma^{-1}

--

- Graphical Models require normal responses

--

- Gaussian Copula models can "transform" to normality
---
# ecoCopula Example
.scroll-box-20[
```{r ecoCopula}
# devtools::install_github("gordy2x/ecoCopula")
library(ecoCopula)
gcgm_obj_0 <- cgr(tas.nb,lambda=0)
plot(gcgm_obj_0)
gcgm_obj_1 <- cgr(tas.nb,lambda=.1)
plot(gcgm_obj_1)
gcgm_obj_2 <- cgr(tas.nb,lambda=.2)
plot(gcgm_obj_2)
gcgm_obj_3 <- cgr(tas.nb,lambda=seq(from = 0, to = 0.2,by = 0.01))
plot(gcgm_obj_3)


```
]
---
class: inverse, center, middle 

# Hierarchical Neural networks 

--- 



